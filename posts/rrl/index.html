<!DOCTYPE HTML>

<html>
  <head>
    <title>Relational Reinforcement Learning</title>
    
    
    <meta name="description" content="This website is the home of Harsha Kokel. A Ph.D. student working with Prof. Sriraam Natarajan at The University of Texas at Dallas" />
    
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="referrer" content="no-referrer">
    
    
    
    <link rel="stylesheet" href="/css/main.min.css" />
    
    
    
    <link rel="stylesheet" href="/css/academicons.min.css"/>
    <link rel="stylesheet" href="/css/ocs-ui.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
     <script src="/js/jquery-3.3.1.min.js"></script>
    <link rel="manifest" href="/site.webmanifest">
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Relational Reinforcement Learning"/>
<meta name="twitter:description" content="The paper came before the goal-conditioned RL, Multi-task RL or Graph Neural Network literature. Major motivation of this paper is to learn a generalizable policy. Generalization in terms of varying number of objects in the domain (for example, in blocks-world number of blocks can change) or change in the goal state (for example, stack red block on blue block instead if green on yellow).
Authors demonstrate that by using approaches from inductive logic programming literature, first-order policy can be learnt which naturally supports both the generalization discussed above."/>

    <meta property="og:title" content="Relational Reinforcement Learning" />
<meta property="og:description" content="The paper came before the goal-conditioned RL, Multi-task RL or Graph Neural Network literature. Major motivation of this paper is to learn a generalizable policy. Generalization in terms of varying number of objects in the domain (for example, in blocks-world number of blocks can change) or change in the goal state (for example, stack red block on blue block instead if green on yellow).
Authors demonstrate that by using approaches from inductive logic programming literature, first-order policy can be learnt which naturally supports both the generalization discussed above." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://harshakokel.com/posts/rrl/" />
<meta property="article:published_time" content="2020-04-12T16:40:08+02:00" />
<meta property="article:modified_time" content="2020-04-12T16:40:08+02:00" /><meta property="og:site_name" content="Harsha Kokel" />

    <meta itemprop="name" content="Relational Reinforcement Learning">
<meta itemprop="description" content="The paper came before the goal-conditioned RL, Multi-task RL or Graph Neural Network literature. Major motivation of this paper is to learn a generalizable policy. Generalization in terms of varying number of objects in the domain (for example, in blocks-world number of blocks can change) or change in the goal state (for example, stack red block on blue block instead if green on yellow).
Authors demonstrate that by using approaches from inductive logic programming literature, first-order policy can be learnt which naturally supports both the generalization discussed above.">
<meta itemprop="datePublished" content="2020-04-12T16:40:08+02:00" />
<meta itemprop="dateModified" content="2020-04-12T16:40:08+02:00" />
<meta itemprop="wordCount" content="282">



<meta itemprop="keywords" content="RL,relational,SRL," />

    
  </head>
  <body>

    
    <div id="wrapper">

      
      <div id="main">
	<div class="inner">

	  
	  
<header id="header">
	<h3><a href="/" style="color:inherit">Harsha Kokel</a></h3>
	<ul class="icons">
		<li id="linkedin">
			<a target="_blank" href="http://linkedin.com/in/harshakokel" title="linkedin" class="icon brands fa-linkedin">
				<span class="label" >Linked in</span>
			</a>
		</li>
		<li id="github">
			<a target="_blank" href="https://github.com/harshakokel" title="github" class="icon brands fa-github">
				<span class="label" >Github</span>
			</a>
		</li>
		<li id="email">
			<a  href="mailto:hkokel@utdallas.edu" title="mail" class="icon solid fa-envelope" >
				<span class="label" >Mail</span>
			</a>
		</li>
		<li id="twitter">
			<a target="_blank" href="https://twitter.com/harsha_kokel" title="twitter" class="icon brands fa-twitter" >
				<span class="label" title="Twitter">Twitter</span>
			</a>
		</li>
	</ul>
</header>
    <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax '})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	  
<div class="page__section">
  <nav class="breadcrumb breadcrumb_type5" aria-label="Breadcrumb">
<ol  class="breadcrumb__list r-list">
  



<li class="breadcrumb__group" >
  <a href="https://harshakokel.com/" class="breadcrumb__point r-link">Home</a>
  <span class="breadcrumb__divider" aria-hidden="true">&raquo;</span>
</li>


<li class="breadcrumb__group"  class="active">
  <a href="https://harshakokel.com/posts/" class="breadcrumb__point r-link">Posts</a>
  <span class="breadcrumb__divider" aria-hidden="true">&raquo;</span>
</li>

  <li class="breadcrumb__group">
    Apr 12, 2020
  </li> 
  <li class="tags">  Tagged with:
      <a href="https://harshakokel.com/tags/rl/" class="button">rl</a>  <a href="https://harshakokel.com/tags/relational/" class="button">relational</a>  <a href="https://harshakokel.com/tags/srl/" class="button">srl</a>
  </li>
</ol> 



</nav>
</div>

  <header class="main">
    <h2>Relational Reinforcement Learning</h2>
  </header>

  
  

  <p><strong></strong></p>
  
    <blockquote>My notes on <strong>Džeroski, Sašo, Luc De Raedt, and Kurt Driessens, Machine Learning 2001</strong></blockquote>
  
  <p><h3 id="heading"></h3>
<p>The paper came before the goal-conditioned RL, Multi-task RL or Graph Neural Network literature. Major motivation of this paper is to learn a <strong>generalizable policy</strong>. Generalization in terms of <strong>varying number of objects</strong> in the domain (for example, in blocks-world number of blocks can change) or <strong>change in the goal state</strong> (for example, stack red block on blue block instead if green on yellow).</p>
<p>Authors demonstrate that by using approaches from inductive logic programming literature, first-order policy can be learnt which naturally supports both the generalization discussed above.</p>
<p>In particular, author propose to learn <strong>Q-Tree</strong> i.e. TILDE-RT (Top-down Induction of Logical decision trees for regression) as Q-Function which take the state and action pair and predict q values. The policy function, <strong>P-Tree</strong>, can then be induced from Q-Tree.</p>
<p>Following Q-RRL algorithm is proposed to learn Q-Tree, which updates the TILDE-RT after every episode. Data set used to learn the TILDE-RT is generated by exploring the environment and P-RRL algorithm is proposed for inducing P-Tree from Q-Tree</p>
<div align="center">
<img align="center" width="800"  src="/images/RRL-QRRL.png">
</div>
<div align="center">
<img align="center" width="800"  src="/images/RRL-PRRL.png">
</div>
<h3 id="critique">Critique</h3>
<ul>
<li>Proposed solution does not seem to scale well specifically because the Logical programs do not scale with higher number of  data points or high dimensional data.</li>
<li>The relational trees might be able to generalize to various number of blocks but I think it will not generalize to different goals. For e.g. if all the training examples had <code>goal(on(.,.))</code> and if the test examples have <code>goal(clear(.))</code>, I do not think the TILDE-RT will be able to achieve that goal.</li>
<li>With Graph Neural Network and goal-conditioned RL, both the generalizations  targeted by Q-RRL are achieved in a scalable manner. So, the only additional benefit RRL really has is the use of domain knowledge, which comes from ILP.</li>
</ul>
</p>



<script src="https://utteranc.es/client.js"
        repo="harshakokel/harshakokel.github.io"
        issue-number=16
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<div class="postpagination">
  
    <a class="postpagination__item prev" href="https://harshakokel.com/posts/few-shot-learning-gnn/">
        <span class="postpagination__label"><i class="fa solid fa-backward"></i> Previous post</span>
        <span class="postpagination__title">Few-Shot Learning with GNN</span>
    </a>
  

  
    <a class="postpagination__item next" href="https://harshakokel.com/posts/relational-network/">
      <span class="postpagination__label">Next post <i class="fa solid fa-forward"></i></span>
      <span class="postpagination__title" >Relational Network</span>
    </a>
  
</div>
<br>



	</div>
      </div>

      
<div id="sidebar">
  <div class="inner">

    <section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="search-by" id="search-by" type="search" placeholder="Search">
									</form>
</section>




<script type="text/javascript" src="/js/lunr.js?1609395147"></script>
<script type="text/javascript" src="/js/auto-complete.js?1609395147"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/harshakokel.com";
    
</script>
<script type="text/javascript" src="/js/search.js?1609395147"></script>

    
<nav id="menu">
  <header class="major">
    <h2>Menu</h2>
  </header>
  <ul>
    
    
    
    <li><a href="/">Homepage</a></li>
    
    
    
    <li><a href="/cv/">cv</a></li>
    
    
    
    <li><a href="/projects/">projects</a></li>
    
    
    
    <li><a href="/posts/">BLOG POSTS</a></li>
    
    
  </ul>
</nav>


    
<footer id="footer">
  <p class="copyright">Powered by <a href="https://gohugo.io">Hugo</a> and design by <a href="https://html5up.net">HTML5 UP</a>.</p>
</footer>


  </div>
</div>


    </div>
    
    
    
    <script src="/js/jquery.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    
    <script src="/js/main.js"></script>
    
      

  </body>
</html>
