<!DOCTYPE HTML>

<html>
  <head>
    <title>Deep Reinforcement Learning With Relational Inductive Biases</title>
    
    
    <meta name="description" content="This website is the home of Harsha Kokel. A Ph.D. student working with Prof. Sriraam Natarajan at The University of Texas at Dallas" />
    
    <meta charset="utf-8" />
    <link rel="preconnect" href="https://fonts.gstatic.com"> 
    <link href="https://fonts.googleapis.com/css2?family=Dawning+of+a+New+Day&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="referrer" content="no-referrer">
    
    
    
    <link rel="stylesheet" href="/css/main.css" />
    
    
    
    <link rel="stylesheet" href="/css/academicons.min.css"/>
    <link rel="stylesheet" href="/css/ocs-ui.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
     <script src="/js/jquery-3.3.1.min.js"></script>
    <link rel="manifest" href="/site.webmanifest">
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deep Reinforcement Learning With Relational Inductive Biases"/>
<meta name="twitter:description" content="Relational RL has not made a lot of splashes in real-world because it is easier to write a planner than learn a relational RL agent. This might be about to change with the current achievements of the graph based relational reasoning approaches. This article summarizes my understanding of the pioneering work of Vinicius Zambaldi et al. (ICLR 2019) on Deep Relational RL."/>

    <meta property="og:title" content="Deep Reinforcement Learning With Relational Inductive Biases" />
<meta property="og:description" content="Relational RL has not made a lot of splashes in real-world because it is easier to write a planner than learn a relational RL agent. This might be about to change with the current achievements of the graph based relational reasoning approaches. This article summarizes my understanding of the pioneering work of Vinicius Zambaldi et al. (ICLR 2019) on Deep Relational RL." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://harshakokel.com/posts/drrl/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-04-15T16:40:08+02:00" />
<meta property="article:modified_time" content="2020-04-15T16:40:08+02:00" /><meta property="og:site_name" content="AI Research Scientist, &lt;br&gt; IBM Research" />

    <meta itemprop="name" content="Deep Reinforcement Learning With Relational Inductive Biases">
<meta itemprop="description" content="Relational RL has not made a lot of splashes in real-world because it is easier to write a planner than learn a relational RL agent. This might be about to change with the current achievements of the graph based relational reasoning approaches. This article summarizes my understanding of the pioneering work of Vinicius Zambaldi et al. (ICLR 2019) on Deep Relational RL."><meta itemprop="datePublished" content="2020-04-15T16:40:08+02:00" />
<meta itemprop="dateModified" content="2020-04-15T16:40:08+02:00" />
<meta itemprop="wordCount" content="441">
<meta itemprop="keywords" content="RL,GNN,neurosymbolic,relational," />
  </head>
  <body>

    
    <div id="wrapper">

      
      <div id="main">
	<div class="inner">

	  
	  
<header id="header">
	<h3><a href="/" style="font-family: 'Dawning of a New Day', cursive;font-size:2em;color: var(--main-highlight-color);font-weight:500">harsha kokel</a></h3>
	<ul class="icons">
		<li id="profile">
			<a  href="/cv" title="CV" class="icon">
				<i class="ai solid ai-cv"></i><span class="label" >CV</span>
			</a>
		</li>
		<li id="linkedin">
			<a target="_blank" href="http://linkedin.com/in/harshakokel" title="linkedin" class="icon brands fa-linkedin">
				<span class="label" >Linked In</span>
			</a>
		</li>
		
		<li id="github">
			<a target="_blank" href="https://github.com/harshakokel" title="github" class="icon brands fa-github">
				<span class="label" >Github</span>
			</a>
		</li>
		<li id="email">
			<a  href="mailto:harsha.kokel@ibm.com" title="mail" class="icon solid fa-envelope" >
				<span class="label" >Mail</span>
			</a>
		</li>
		<li id="twitter">
			<a target="_blank" href="https://twitter.com/harsha_kokel" title="twitter" class="icon brands fa-twitter" >
				<span class="label" title="Twitter">Twitter</span>
			</a>
		</li>
	</ul>
</header>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous" onload="renderMathInElement(document.body,{delimiters: [
  {left: '$$', right: '$$', display: true},
  {left: '$', right: '$', display: false},
  {left: '\\(', right: '\\)', display: false},
  {left: '\\[', right: '\\]', display: true}
]});"></script>




	  
<div class="page__section">
  <nav class="breadcrumb breadcrumb_type5" aria-label="Breadcrumb">
<ol  class="breadcrumb__list r-list">
  



<li class="breadcrumb__group" >
  <a href="https://harshakokel.com/" class="breadcrumb__point r-link">Home</a>
  <span class="breadcrumb__divider" aria-hidden="true">&raquo;</span>
</li>


<li class="breadcrumb__group"  class="active">
  <a href="https://harshakokel.com/posts/" class="breadcrumb__point r-link">Posts</a>
  <span class="breadcrumb__divider" aria-hidden="true">&raquo;</span>
</li>

  <li class="breadcrumb__group">
    Apr 15, 2020
  </li> 
  <li class="tags crumb"> 
      <a href="https://harshakokel.com/tags/rl/" class="tag__link">rl</a>  <a href="https://harshakokel.com/tags/gnn/" class="tag__link">gnn</a>  <a href="https://harshakokel.com/tags/neurosymbolic/" class="tag__link">neurosymbolic</a>  <a href="https://harshakokel.com/tags/relational/" class="tag__link">relational</a>
  </li>
</ol> 



</nav>
</div>

  <header class="main">
    <h2>Deep Relational RL</h2>
  </header>

  
  
  
 
  
  
  
    <blockquote class="preview">Relational RL has not made a lot of splashes in real-world because it is easier to write a planner than learn a relational RL agent. This might be about to change with the current achievements of the graph based relational reasoning approaches. This article summarizes my understanding of the pioneering work of Vinicius Zambaldi et al. <a href="https://openreview.net/forum?id=HkxaFoC9KQ" target="_blank">(ICLR 2019)</a> on Deep Relational RL. </blockquote>
  
  
  <p><p>Deep RL methods have been every effective but they have poor generalization capability, especially combinatorial generalization (for eg. if the number of blocks are changed in the blocks world). Recent advances in graph network literature have achieved combinatorial generalization by learning neural network that can reason about relationship of various nodes in graphs. Since this reasoning happens pairwise, the algorithms are able to scale to varying number of objects.</p>
<p>In this paper, authors introduce how multi-headed dot product attention can be used to perform relational reasoning in model-free deep RL and hence achieve combinatorial generalization.</p>
<h3 id="multi-head-dot-product-attention-mhdpa">Multi-Head Dot Product Attention (MHDPA)</h3>
<p>This is the self attention mechanism proposed in the paper Vaswani et al. NeurIPS 2017, Attention is all you need. In that paper, the MHDPA was used on an input of word embeddings but in general it can be any form of entities. Check out the neat explanation of MHDPA by Jay Alammar <a href="https://jalammar.github.io/illustrated-transformer/" target="_blank">here</a></p>
<p>On a very high level, attention mechanism</p>
<ol>
<li>converts these entities ($X$) to Queries ($Q$), Keys ($K$) and Values ($V$) <sup><a href="#stack-ref">1</a></sup>,</li>
<li>computes the similarity score between each query and key $QK^{T}$,</li>
<li>scales and normalizes it to a distribution: $\operatorname{Softmax}(\frac{Q.K^{T}}{\sqrt{d}})$.</li>
<li>outputs the weighted values based on this distribution: $Z = \operatorname{Softmax}(\frac{Q.K^{T}}{\sqrt{d}})\cdot V$</li>
</ol>
<p>Multi headed version of attention does two additional steps</p>
<ol>
<li>Concatenates all the attention outputs $(\mathbin\Vert_i Z_i)$</li>
<li>Transform it original $X$ dimension by multiplying it with weight matrix $W$</li>
</ol>
<div align="center">
<img align="center" width="800"  src="/images/MHDPA.png">
<p>src: <a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer by Jay Alammar</a>
</div>
<h3 id="summary">Summary</h3>
<p>Zambaldi et al. proposes to use the MHDPA (with image embeddings as entities) to perform relational-reasoning while training a network for distributed A2C model. First the images from the box-world domain are processed through a convolutional neural network in the &ldquo;input module&rdquo;. The spatial representation learnt from the CNN is then used as embedding after concatenating $x$ and $y$ co-ordinate as additional features. MHDPA is used to perform manipulations between this entities a.k.a. relational-reasoning. Finally the multiple attention heads are aggregated by another multi-layered-perceptron $g_\theta$ (instead of the weight matrix $W$ used in Vaswani et al. 2017). Then in output module, max-pooling is performed and a FC layer converts it to actor policy $\pi$ and critic&rsquo;s state-value (or advantage value) $B$.</p>
<div align="center">
<img align="center" width="1000"  src="/images/DRRL-architecture.png">
</div>
<blockquote>
<p>Authors mention that the use of a $g_\theta$, a non-linear MLP, in the final stage is aligned with the use of MLP in relational-network paper where a MLP is used to manipulate the relation embeddings.</p>
</blockquote>
<p>Qualitative Analysis of the attention heads show that they infact learn lock-key relationship and also a relationship between agent and entities.</p>
<div align="center">
<img align="center" width="1000"  src="/images/DRRL-attention.png">
</div>
<h3 id="references">References</h3>
<ul>
<li><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank">Illustrated Transformer</a></li>
<li><sup><a name="stack-ref">1</a></sup><a href="https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms" target="_blank">What exactly are keys, queries, and values in attention mechanisms?
</a></li>
<li><a href="https://theaisummer.com/Actor_critics/" target="_blank">The idea behind Actor-Critics and how A2C and A3C improve them</a></li>
</ul>
</p>



<script src="https://utteranc.es/client.js"
        repo="harshakokel/harshakokel.github.io"
        issue-number=18
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<div class="postpagination">
  
    <a class="postpagination__item prev" href="https://harshakokel.com/posts/relational-network/">
        <span class="postpagination__label"><i class="fa solid fa-backward"></i> Previous post</span>
        <span class="postpagination__title">Relational Network</span>
    </a>
  

  
    <a class="postpagination__item next" href="https://harshakokel.com/posts/skills-to-symbols/">
      <span class="postpagination__label">Next post <i class="fa solid fa-forward"></i></span>
      <span class="postpagination__title" >Learning Symbolic Representations for planning</span>
    </a>
  
</div>
<br>



	</div>
      </div>

      
<div id="sidebar">
  <div class="inner">

    <section id="search" class="alt">
										<input type="text" name="search-by" id="search-by" type="search" placeholder="Search">
</section>




<script type="text/javascript" src="/js/lunr.js?1761158476"></script>
<script type="text/javascript" src="/js/auto-complete.js?1761158476"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/harshakokel.com";
    
</script>
<script type="text/javascript" src="/js/search.js?1761158476"></script>

    
<nav id="menu">
  <h2>hk</h2>
  
  <ul>
    
    
    
    <li><a href="/">Homepage</a></li>
    
    
    
    <li><a href="/publications/">Publications</a></li>
    
    
    
    <li><a href="/posts/">BLOG POSTS</a></li>
    
    
  </ul>
</nav>

    
    
    <section class="nav">
									<div class="mini-posts">
										<article>
                      <span class="mini-post-misc"><a href="/misc">miscellaneous</a></span>
											<a href="/misc" class="image"><img src="/images/Smile.png" alt=""></a>
										</article>
                    </div>
   </section>
  
    
<footer id="footer">
  <p class="copyright">Powered by <a href="https://gohugo.io">Hugo</a> and design by <a href="https://html5up.net">HTML5 UP</a>.</p>
</footer>


  </div>
</div>


    </div>
    
    
    
    <script src="/js/jquery.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    
    <script src="/js/main.js"></script>
    
      

  </body>
</html>
